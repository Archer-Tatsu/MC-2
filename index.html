<!DOCTYPE html>
<html>
	<head>
		<meta charset="utf-8" />
		<title>MC^2 Lab</title>
		<link rel="stylesheet" href="css/index.css" />
		<script src="js/jquery-3.2.1.min.js"></script>
		<script type="text/javascript" src="js/head.js"></script>
	</head>
	<body>
		
		<div class="bg">
			<div style="padding:200px 0 0 0;">
			Welcome to <br/>
			Multimedia Computing Towards Communications<br/>
			(MC<sup>2</sup>) Lab
			</div>		
			
		</div>
		<div class="thisBrief">  
			<h1>Lab Introduction</h1>
			
			The MC<sup>2</sup> lab targets at improving the efficiency of multimedia communication by developing multimedia computing approaches, benefiting from the success of computer vision and machine learning techniques. Specifically, along with the explosion of multimedia content, multimedia communications have become increasingly prominent in communication networks, affecting the daily life of billions of citizens and millions of businesses in the world. The popularity, as a consequence, inceases the amount of data over networks, which is expected to grow almost 40-fold in the next five years. Given the limited spectrum, multimedia applications have encountered the bandwidth-hungry bottleneck. On one hand, high spectral efficiency has been an ongoing request in communication development. On the other hand, pioneering research on delivering the perceived content of human is relieving the bandwidth-hungry issue from the perspective of perceptual compression and coding, in which computer vision and machine learning techniques have been actively studies. This is, however, what the MC<sup>2</sup> is focusing on, that is, incorporating the state-of-the-art computer vision and machine learning methodologies into image/video compression and transmission to improve the efficiency of multimedia communications.
			
			<h1>News Update</h1>
			<ul class=news>
                <li><strong>[2020-01-13]</strong>
                Our paper entitled “State-of-the-art in 360° Video/Image Processing: Perception, Assessment and Compression” has been accepted by IEEE Journal of Selected Topics in Signal Processing (JSTSP). Congratulations, Chen Li.
                </li>
                <li><strong>[2019-10-03]</strong>
                Our paper entitled “An EM-based User Clustering Method in Non-orthogonal Multiple Access” has been accepted by IEEE Transactions on Communications (TCOM). Well done, Jie Ren.
                </li>
                <li><strong>[2019-09-27]</strong>
                Our paper entitled “MFQE 2.0: A New Approach for Multi-frame Quality Enhancement on Compressed Video” has been accepted by IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI, IF=17.730). Congratulations, Qunliang Xing.
                </li>
                <li><strong>[2019-09-03]</strong>
                Our paper entitled "A Meta-learning Framework for Learning Multi-User Preferences in QoE Optimization of DASH" has been accepted by IEEE Transactions on Circuits and Systems for Video Technology (TCSVT). Well done, Liangyu Huo.
                </li>
                <li><strong>[2019-07-22]</strong>
                Our paper entitled “Wavelet Domain Style Transfer for an Effective Perception-distortion Tradeoff in Single Image Super-Resolution” has been accepted by IEEE International Conference on Computer Vision (ICCV'19), oral presentation. Congratulations, Xin Deng. <a href=" https://github.com/cindydeng1991/Wavelet-Domain-Style-Transfer-for-an-Effective-Perception-distortion-Tradeoff-in-Single-Image-Super-">[Software]</a><a href=" https://www.youtube.com/watch?v=HwMWViC08Zc&list=PLBAFw2oKatLJ7Mb8Xat6fq_oGyD7JdaNU&index=6">[Video presentation]</a>
                </li>
                <li><strong>[2019-07-03]</strong>
                Our paper entitled “A Large-scale Database and a CNN Model for Attention Based Glaucoma Detection” has been accepted by IEEE Transactions on Medical Imaging (TMI). Well done, Liu Li.
                </li>
                <li><strong>[2019-06-30]</strong>
				Our paper entitled "Pathology-aware deep network visualization and its application in glaucoma image synthesis" has been accepted by MICCAI'19. Congratulations, Xiaofei Wang.
                </li>
                <li><strong>[2019-06-02]</strong>
				Our paper entitled "DeepMTT: A Deep Learning Maneuvering Target-Tracking Algorithm Based on Bidirectional LSTM Network" has been accepted by Information Fusion. Well done, Jingxian Liu.
                </li>
                <li><strong>[2019-05-30]</strong>
				Our paper entitled "A Deep Learning Approach for Multi-Frame In-Loop Filter of HEVC" has been accepted by IEEE Transactions on Image Processing (TIP). Congratulations, Tianyi Li. 
                </li>
                <li><strong>[2019-03-10]</strong>
				Our papers entitled “Removing Rain in Videos: A Large-scale Database and a Two-stream Convlstm Approach” and “Quality-gated Convolutional LSTM for Enhancing Compressed Video” have been accepted by ICME'19 for oral presentations. Well done, Tie Liu and Ren Yang.
                </li>
                <li><strong>[2019-03-06]</strong>
				Our co-authored paper entitled “Learning QoE of Mobile Video Transmission with Deep Neural Network: A Data-driven Approach” has been accepted by IEEE JSAC.
                </li>
				<li><strong>[2019-02-25]</strong>
				Our papers entitled “Viewport Proposal CNN for 360° Video Quality Assessment” and “Attention Based Glaucoma Detection: A Large-scale Database and CNN Model” have been accepted by CVPR'19. Well done, Chen Li and Liu Li.
                </li>
                <li><strong>[2019-02-02]</strong>
                Three of our papers have been accepted by ICASSP.
                </li>
				<li><strong>[2019-01-15]</strong>
				We are organizing a special issue of IEEE J-STSP (IF: 4.361), the title of which is Perception-driven 360-degree video processing. Please see <a href="pdf/JSTSP_SI_360_CFP.pdf">Call for Paper</a>. 
                </li>

				<li><a href="news.html">More ...</a></li>
			</ul>
			
		</div>
	</body>
	<script type="text/javascript" src="js/foot.js"></script>
</html>
