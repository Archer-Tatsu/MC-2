<!DOCTYPE html>
<html>
	<head>
		<meta charset="UTF-8">
		<title>Databases &amp; Codes</title>
		<link rel="stylesheet" href="../css/normal.css" />
		<script type="text/javascript" src="../js/head2.js"></script>
	</head>
	<body>
		<div class="banner" style="color:white; text-align: center;font-size: 45px;font-weight: bold;">
			Databases &amp; Codes
		</div>
		<div class="mainbody">
			<h2>Saliency Detection</h2>
			<hr/>
			<ul>
				<li class="content">
					<h3>Code of RSRCNN</h3>
					The code of the Road structure refined CNN(RSRCNN).
					<br/>|
					<a href='https://github.com/yananweinbaa/RSRCNN'>Download Code</a>
					|
				</li>
				<li class="content">
					<h3>Raw video dataset</h3>
					33 raw videos from the latest HEVC standard test sets, such as JCT-VC, which have been commonly utilized for evaluating HEVC performance.  The eye fixations of all 32 subjects over each video frame were recorded by a Tobii TX300 eye tracker at a sample rate of 300 Hz.
					<br/>|
					<a href='https://github.com/remega/video_database'>Download Database</a>
					|
				</li>
				<li class="content">
					<h3>Large-scale Eye-tracking Database of Videos (LEDOV)</h3>
					LEDOV includes 538 videos with diverse content, containing a total of 179,336 frames and 6,431 seconds. The diverse content refers to the daily action, sports, social activity and art performance of human, and the videos of animal and man-man objects are also included. Moreover, 32 participants (18 males and 14 females), aging from 20 to 56 (32 on average), were recruited to participate in the eye-tracking experiment.
					<br/>|
					<a href='https://github.com/remega/LEDOV-eye-tracking-database'>Download Database</a>
					|
				</li>
				<li class="content">
					<h3>Predicting Salient Face in Multiple-face Videos</h3>
					Eye tracking data on multiple face videos.
					<br/>|
					<a href='https://github.com/yufanLIU/salient-face-in-MUVFET'>Download Database</a>
					|
				</li>
				<li class="content">
					<h3>Natural-scene Images Memorability (NSIM) Database</h3>
					NSIM dataset includes 258 natura-scene images and their memorability scores.
					<br/>|
					<a href='https://github.com/Blossomsblue/Memorability'>Download Database</a>
					|
				</li>
				<li class="content">
					<h3>Face images for saliency detection</h3>
					510 Face images for saliency detection.
					<br/>|
					<a href='https://github.com/RenYun2016/Face'>Download Database</a>
					|
				</li>
				<li class="content">
					<h3>Face videos for saliency detection</h3>
					Face videos for saliency detection.
					<br/>|
					<a href='https://github.com/RenYun2016/-Particle-Filter-for-Dynamic-GMM'>Download Database</a>
					|
				</li>
			</ul>
			<h2>Video Compression</h2>
			<hr/>
			<ul>
				
				<li class="content">
					<h3>Database for HEVC in-loop filter</h3>
					A large-scale database for HEVC in-loop filter (HIF).
					<br/>|
					<a href='https://github.com/tianyili2017/HIF-Database'>Download Database</a> |
				</li>
				
				<li class="content">
					<h3>Subjective-driven Complexity Control Approach for HEVC</h3>
					Subjective-driven Complexity Control Source Code.
					<br/>|
					<a href='https://github.com/cindydeng1991/DENG_TCSVT/'>Download Code</a>
					|
				</li>
				<li class="content">
					<h3>Eye-tracking database for 40 typical images</h3>
					An eye-tracking database for 40 typical images.
					<br/>|
					<a href='https://drive.google.com/drive/folders/0ByJ_K4vlqqQLTDg4R29QY3F0Qzg'>Download Database</a>
					|
				</li>
				<li class="content">
					<h3>Database for CU partition of HEVC (CPH)</h3>
					A large-scale database for CU partition of HEVC, to reduce encoding complexity through deep learning based approach.
					<br/>|
					<a href='https://github.com/tianyili2017/CPH'>Download Database</a>
					|
					<a href='https://github.com/tianyili2017/HEVC-Complexity-Reduction'>Download Code</a>
					|
				</li>
				<li class="content">
					<h3>Code of DS-CNN</h3>
					The Caffe code of the Decoder-side Scalable Convolutional Neural Network (DS-CNN).
					<br/>|
					<a href='https://github.com/ryangBUAA/DS-CNN'>Download Code</a>
					|
				</li>
				<li class="content">
					<h3>RTE core</h3>
					The core code for the recursive Taylor expansion (RTE) method.
					<br/>|
					<a href='https://sites.google.com/site/lsxweb/Home/publication/tcsvt2016source'>Download Code</a>
					|
				</li>
				<li class="content">
					<h3>Weight-based R-lambda RC</h3>
					The core code for the weight-based R-lambda rate control.
					<br/>|
					<a href='https://sites.google.com/site/lsxweb/Home/publication/spic2015source'>Download Code</a>
					|
				</li>
			</ul>
			<h2>Virtual/Augmented Reality</h2>
			<hr/>
			<ul>
				<li class="content">
					<h3>NCP- and CP-PSNR</h3>
					Perceptual objective quality assessment methods of omnidirectional video.
					<br/>|
					<a href = "https://github.com/Archer-Tatsu/CP-PSNR">Download Code</a>
					|
				</li>
				<li class="content">
					<h3>Panoramic Video Head Tracking Data</h3>
					HTC Vive head tracking data of 40 subjects on 48 panoramic video sequences in 8 classes.
					<br/>|
					<a href='https://github.com/Archer-Tatsu/head-tracking'>Download Database</a>
					|
				</li>
				<li class="content">
					<h3>Evaluation_VR</h3>
					A subjective evaluation tool on VR video with GUI in MATLAB. SSCQS and MSCQS method are provided for different aims.
					<br/>|
					<a href='https://github.com/Archer-Tatsu/Evaluation_VR-onebar-vive'>Download Code</a>
					|
				</li>
			</ul>
		</div>
	</body>
	<script type="text/javascript" src="../js/foot2.js"></script>
</html>
